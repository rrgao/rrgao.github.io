<!DOCTYPE html>
<html>
<head>
    <title>Rongrong GAO</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome-4.7.0/css/font-awesome.min.css" rel="stylesheet"> <!--icon: fa fa-home, etc.-->

    <!-- Custom Styles -->
    <style>
        body {
            margin-top: -20px;
            font-family: Roboto, 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;   
        }
        h1 {
            font-weight: 300;
            font-size: 2rem;
        }
        #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
        }
        #footer {
            background-color: #FFFFFF;
            padding:60px;
        }
        #portrait {
            border: 0px solid white;
        }
        #header-text {
            margin-top: 60px;
            margin-left: 220px;
        }
        #header-text-name {
            font-size: 40px;
        }
        #header-text-title {
            font-size: 17px;
        }
        #header-text-affiliation {
            font-size: 17px;
            margin-top: 10px;
        }
        a {
            color: #337ab7;
            text-decoration: none;
        }
        #header-text-email {
            margin-top: 15px;
            font-size: 15px;
            /* font-style: italic; */
        }
        #header-text-others {
            margin-top: 15px;
            font-size: 17px;
        }
        #header-text-others a {
            color: #337ab7;
            text-decoration: none;
        }
        .header-text-desc {
            font-size: 20px;
        }
        .vspace-top {
            margin-top: 30px;
        }
        .vspace-top-news {
            margin-top: 15px;
        }
        .paper-image {
            width: 150px;
        }
        .news-date {
            font-weight: bold;
        }
        .paper-title {
            font-weight: bold;
        }
        .paper-authors {
            font-style: normal;
        }
        .paper-desc {
            font-style: italic;
        }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-3 offset-sm-1">
                    <img src='imgs/portrait.png' class='img-fluid' id='portrait' style=‘width:200px; height:auto;’>
                </div>

                <div class="col">
                    <div id='header-text-name'>
                        <strong>Rongrong GAO</strong>
                    </div>
                      <div id='header-text-title'>
                           <br>I received my doctoral degree from Hong Kong University of Science and Technology</>, supervised by <a href="https://cqf.io/">Prof. Qifeng Chen</a>. 
                           Before that, I received my B.S. and M.S. degrees from <a href="http://www.lmars.whu.edu.cn"> Wuhan University</a> under the supervision of <a href="http://www.lmars.whu.edu.cn/prof_web/zhongyanfei/e-index.html">Prof. Yanfei Zhong</a> and <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html">Prof. Liangpei Zhang</a>. 
                           My research interests include multi-modal data (RGB/RGBI/RGBD/LIDAR) perception and AIGC watermark.
                      </div>
                      <div id='header-text-email'>
                          <br>Cooperation is warmly welcomed, and I will code, conduct experiments, and write papers.
                               Please write to me: rongronggao1804@gmail.com
                      <!--<i class="fa fa-home" aria-hidden="true" style="font-size:17px"></i>&nbsp; Clear Water Bay, Kowloon, Hong Kong, China <br> -->
                      <!--<i class="fa fa-envelope-o" aria-hidden="true" style="font-size:16px"></i>&nbsp; rongronggao1804@gmail.com;</br> -->
                      <!--<i class="fa fa-envelope-o" aria-hidden="true" style="font-size:16px"></i>&nbsp;-->
                      </div> 
                      <div id='header-text-others'>
                           <i class="fa fa-google" aria-hidden="true" style="font-size:17px"></i> <a href="https://scholar.google.com/citations?user=MwdwZ_kAAAAJ&hl=zh-CN&oi=ao"> Google Scholar</a>
                           &nbsp;&nbsp;&nbsp;&nbsp; 
                           <i class="fa fa-github" aria-hidden="true" style="font-size:17px"></i> <a href="https://github.com/rrgao?"> GitHub</a> 
                           &nbsp;&nbsp;&nbsp;&nbsp;
                           <i class="fa fa-linkedin" aria-hidden="true" style="font-size:17px"></i> <a href="https://github.com/rrgao?"> Linkedin</a> 
                           &nbsp;&nbsp;&nbsp;&nbsp;
                      </div>
                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <!-- Biography -->
                <!--<h3><strong>Biography</strong></h3><hr>
                <p style="font-size:17px">
                    I received my doctoral degree from Hong Kong University of Science and Technology</>, supervised by <a href="https://cqf.io/">Prof. Qifeng Chen</a>. 
                    Before that, I received my B.S. and M.S. degrees from <a href="http://www.lmars.whu.edu.cn"> Wuhan University</a> under the supervision of <a href="http://www.lmars.whu.edu.cn/prof_web/zhongyanfei/e-index.html">Prof. Yanfei Zhong</a> and <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html">Prof. Liangpei Zhang</a>. 
                    My research interests include multi-modal data (RGB/RGBI/RGBD/LIDAR) perception and AIGC watermark.
                </p>-->

                <!-- News -->
                <!-- <div class='vspace-top'>
                    <h3><strong>News</strong></h3><hr>
                </div>
                <ul>
                    <li><strong>[02/2023]:</strong> One papers are accepted to xxx 2023.</li>
                </ul> -->

                <!-- ------------------------------------------------------------------------- -->
                <!-- Publications -->
                <!-- <div class='row vspace-top'>
                    <!-- <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="groundplans/thumbnail.mp4" type="video/mp4">
                        </video> 
                    </div>-->

                <div class='vspace-top'>
                    <h3><strong>Publications</strong></h3><hr>
                </div>
                    
                <div class='vspace-top'><h4>Preprints</h4></div>
                    
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Backdoor watermarking in a Generative Model for Copyright Protection
                        </div>
                        <div class='paper-authors'>
                            <u>Rongrong Gao</u>
                        </div>
                        <div class='paper-desc'>
                            Preprint, 2024
                        </div>
                        <div>
                            <!--<a href="">[Project]</a>
                            <a href="">[arxiv]</a>
                            <a href="">[code]</a>-->
                        </div>
                    </div>
                </div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2024PRE-EMD.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            A Cross-modality Embedding Framework in Latent Space
                        </div>
                        <div class='paper-authors'>
                            <u>Rongrong Gao</u>
                        </div>
                        <div class='paper-desc'>
                            Preprint, 2024
                        </div>
                        <div>
                            <!--<a href="">[Project]</a>
                            <a href="">[arxiv]</a>
                            <a href="https://github.com/rrgao/Visible_RGBD">[code]</a>-->
                        </div>
                    </div>
                </div> 

                <div class='vspace-top'><h4>Papers</h4></div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2025ISPRS-HATFormer.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            HATFormer: Height-Aware Transformer for Multimodal 3D Change Detection
                        </div>
                        <div class='paper-authors'>
                            Biyuan Liu, Zhou Huang, Yanxi Li, <u>Rongrong Gao</u>, HuaiXin Chen, TianZhu Xiang
                        </div>
                        <div class='paper-desc'>
                            ISPRS, 2025
                        </div>
                        <div>
                            <a href="">[project]</a>
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271625002485">[paper]</a>
                            <a href="https://github.com/HATFormer/HATFormer">[code]</a>
                        </div>
                    </div>
                </div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2025TIP-UAT.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Uncertainty-Aware Transformer for Referring Camouflaged Object Detection
                        </div>
                        <div class='paper-authors'>
                            Ranwan Wu, TianZhu Xiang, Guo-Sen Xie, <u>Rongrong Gao</u>, Xiangbo Shu, Fang Zhao, Lin Shao
                        </div>
                        <div class='paper-desc'>
                            TIP, 2025
                        </div>
                        <div>
                            <a href="">[project]</a>
                            <a href="https://ieeexplore.ieee.org/document/11080234">[paper]</a>
                            <a href="https://github.com/CVL-hub/UAT">[code]</a>
                        </div>
                    </div>
                </div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2025EJCAI-COD.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Scribble-based Weakly Supervised Camouflaged Object Detection via SAM-guided Feature Correlation Transformer
                        </div>
                        <div class='paper-authors'>
                            Zijie Wu, <u>Rongrong Gao</u>, TianZhu Xiang
                        </div>
                        <div class='paper-desc'>
                            ECAI, 2025
                        </div>
                        <div>
                            <!--<a href="">[Project]</a>-->
                            <!--<a href="https://arxiv.org/abs/2207.14083.pdf">[arxiv]</a>-->
                            <!--<a href="https://github.com/dongbo811/UQFormer?utm_source=catalyzex.com">[code]</a>-->
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2024PHD.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Multi-modal Data Fusion and Sensing for Complex Indoor Scenes
                        </div>
                        <div class='paper-authors'>
                            Rongrong GAO
                        </div>
                        <div class='paper-desc'>
                            HKUST Thesis, 2024
                        </div>
                        <div>
                            <!-- <a href="">[Project]</a> -->
                            <a href="https://drive.google.com/uc?export=download&id=1foyT5dwHGx6XcAPf4kvwRZV80FXuZI6t">[pdf]</a>
                            <a href="https://drive.google.com/uc?export=download&id=1gEJW6gh9ddjx3e3lEV8eBHfc6TYFUhqk">[slides]</a>
                        </div>
                    </div>
                </div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2023MM-segmentation.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            A Unified Query-based Paradigm for Camouflaged Instance Segmentation
                        </div>
                        <div class='paper-authors'>
                            Bo Dong, Jialun Pei, <u>Rongrong Gao</u>, Tianzhu Xiang, Shuo Wang, Huan Xiong
                        </div>
                        <div class='paper-desc'>
                            ACM MM, 2023
                        </div>
                        <div>
                            <a href="">[project]</a>
                            <a href="https://arxiv.org/pdf/2308.07392.pdf">[paper]</a>
                            <a href="https://github.com/dongbo811/UQFormer?utm_source=catalyzex.com">[code]</a>
                        </div>
                    </div>
                </div>
                
               <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2023EJCAI-Diffusion.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Diffusion Model for Camouflaged Object Detection
                        </div>
                        <div class='paper-authors'>
                            Zhennan Chen, <u>Rongrong Gao</u>, Tianzhu Xiang, Lin Fan
                        </div>
                        <div class='paper-desc'>
                            ECAI, 2023
                        </div>
                        <div>
                            <a href="">[project]</a>
                            <a href="https://arxiv.org/pdf/2308.00303.pdf">[paper]</a>
                            <a href="https://github.com/ZNan-Chen/diffCOD">[code]</a>
                        </div>
                    </div>
                </div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2023ICRA-PC.jpg' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Scene-level Point Cloud Colorization with Semantic-and-Geometric-aware Networks
                        </div>
                        <div class='paper-authors'>
                            <u>Rongrong Gao</u>, Tian-Zhu Xiang, Chenyang Lei, Jaesik Park, Qifeng Chen
                    </div>
                        <div class='paper-desc'>
                             ICRA, 2023
                        </div>
                        <div>
                            <a href="https://rrgao.github.io/projects/ICRA23/index.html">[project]</a>
                            <a href="https://cqf.io/papers/Point_Cloud_Colorization_ICRA2023.pdf">[paper]</a>
                            <a href="https://github.com/rrgao/Point_Cloud_Colorization">[code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2021IROS-TOF.png' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data
                        </div>
                        <div class='paper-authors'>
                            <u>Rongrong Gao*</u>, Na Fan*, Changlin Li, Wentao Liu, Qifeng Chen
                    </div>
                        <div class='paper-desc'>
                            IROS, 2021
                        </div>
                        <div>
                            <a href="https://rrgao.github.io/projects/IROS21/index.html">[project]</a>
                            <a href="https://arxiv.org/abs/2108.03649">[paper]</a>
                            <a href="https://github.com/rrgao/Joint_Depth_Normal_Estimation">[code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2020CVPR-future.png' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Future video synthesis with object motion prediction
                        </div>
                        <div class='paper-authors'>
                            Yue Wu, <u>Rongrong Gao</u>, Jaesik Park, Qifeng Chen
                    </div>
                        <div class='paper-desc'>
                            CVPR, 2020
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2004.00542">[paper]</a>
                            <a href="https://github.com/YueWuHKUST/CVPR2020-FutureVideoSynthesis">[code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2016TGRS-segmentation.png' class='img-fluid'>
                    </div>
                    <div class="col">
                        <div class='paper-title'>
                            Multiscale and Multifeature Normalized Cut Segmentation for High Spatial Resolution Remote Sensing Imagery
                        </div>
                        <div class='paper-authors'>
                            Yanfei Zhong, <u>Rongrong Gao</u>, Liangpei Zhang
                    </div>
                        <div class='paper-desc'>
                            TGRS, 2016
                        </div>
                        <div>
                            <a href="https://ieeexplore.ieee.org/abstract/document/7506266">[paper]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/2015IPT-fusion.png' class='img-fluid'>
                    </div>
                    <div class="col">
                      <div class='paper-title'>
                        A Fusion Algorithm for Infrared and Visible Images Based on Adaptive Dual-channel Unit-linking PCNN in NSCT Domain
                      </div>
                      <div class='paper-authors'>
                        Tianzhu Xiang, Li Yan*, <u>Rongrong Gao</u>
                    </div>
                      <div class='paper-desc'>
                        Infrared Physics & Technology, 2015
                      </div>
                      <div>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1350449515000031">[paper]</a>
                      </div>
                    </div>
                </div>
                <!-- ------------------------------------------------------------------------- -->

                <!-- Experiences -->
                <div class='vspace-top'>
                    <h3><strong>Professional Experience</strong></h3><hr>
                </div>
                <ul class="list-inline">
                    <li> NVIDIA: Sim-to-real dataset construction.  2023.03 - 2023.06</li>
                    <li> Allybot: Autonomous robotics algorithm development.  2018 - 2019</li>
                    <li> Sensetime: Computer vision algorithm development.  2017 - 2018</li>
                </ul>


                <!-- Awards -->
                <div class='vspace-top'>
                    <h3><strong>Selected Awards</strong></h3><hr>
                </div>
                <ul class="list-inline">
                    <li>Hong Kong PhD Fellowship (HKPFS).  2019-2024</li>
                    <li>Outstanding Graduates.  (Ranking 1/378)</li> 
                    <li>National scholarships.  2012, 2013, 2014, 2016</li>
                </ul>

            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top' style="text-align: center;">
        &copy; 2023 Rongrong Gao | Thank <a href="https://www.vincentsitzmann.com/">Vincent Sitzmann</a> for sharing the source code of his personal page.
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
